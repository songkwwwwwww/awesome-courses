마지막 수업에서, 우리는 강력한 기계 학습 모델인 피드 포워드 신경망을 도입했다. 우리는 물체 감지, 의미론적 세분화 및 깊이 추정과 같이 이 모델이 수행하기를 원하는 작업을 보았다. 이 수업에서, 우리는 먼저 기계 학습 알고리즘을 설계하는 일반적인 과정을 검토할 것이다. 그런 다음 손실 기능 선택을 포함한 특정 인식 작업에 적합한 신경망을 정의하는 데 여전히 필요한 누락된 구성 요소를 도입할 것입니다. 일반적인 기계 학습 알고리즘 설계 과정부터 시작합시다. 일반적으로, 신경망을 포함한 감독된 기계 학습 모델에는 추론과 훈련의 두 가지 작동 모드가 있다. 리콜은 기본적인 신경망 제형이다. 매개 변수 데이터 집합이 주어지면, 입력 x는 출력 y를 얻기 위해 x의 모델 f와 데이터를 통과한다. 이 작동 모드는 추론이라고 불리며, 보통 우리가 보통 현실 세계에 기계 학습 알고리즘을 배포하는 것이다. 네트워크와 그 매개 변수는 고정되어 있으며 우리는 그것을 사용하여 새로운 입력 데이터에서 인식 정보를 추출합니다. 그러나, 우리는 여전히 매개 변수 세트 데이터를 얻는 방법을 정의해야 한다. 여기서 우리는 네트워크 매개 변수를 통한 최적화와 관련된 두 번째 작동 모드가 필요합니다. 이 모드는 훈련이라고 불리며 당면한 작업에 대한 만족스러운 매개 변수를 생성하는 유일한 목적을 가지고 있습니다. 훈련이 보통 어떻게 수행되는지 봅시다. 우리는 추론과 같은 워크플로우로 시작합니다. 그러나, 훈련 중에 우리는 훈련 데이터를 가지고 있다. 따라서 우리는 x의 f 별이 무엇인지, 모델의 예상 출력이다. 자율주행의 경우, 이 훈련 데이터는 종종 생산하는 데 오랜 시간이 걸리는 인간의 주석이 달린 이미지의 형태를 취한다. 우리는 손실이나 비용 함수를 통해 추론을 예측된 출력 y, x의 실제 출력 f 별과 비교합니다. 손실 함수는 네트워크에서 예측된 출력 y와 x의 진정한 출력 f 별을 입력으로 취하고, 둘 사이의 차이의 척도를 제공한다. 우리는 보통 네트워크의 출력 y가 x의 f 별과 가능한 한 유사하도록 매개 변수 데이터를 수정하여 이 측정을 최소화하려고 노력합니다. 우리는 최적화 절차를 통해 데이터에 대한 이 수정을 수행합니다. 이 최적화 절차는 손실 함수의 출력을 취하고 손실 함수에 대해 더 낮은 값을 제공하는 새로운 매개 변수 데이터 세트를 제공합니다. 우리는 다음 수업에서 이 최적화 과정에 대해 자세히 배울 것이다. 하지만 지금은 설계 과정을 신경망으로 확장합시다. 우리는 마지막 수업에서 입력 x를 취하고 숨겨진 레이어의 시퀀스를 통과한 다음, 출력 레이어를 통해 숨겨진 레이어의 출력을 전달하는 피드 포워드 신경망에 대해 논의했습니다. 이것은 신경망의 추론 단계의 끝이다. 훈련을 위해, 우리는 손실 함수를 통해 예측된 출력을 전달한 다음 최적화 절차를 사용하여 손실 함수에 대해 더 낮은 값을 제공하는 새로운 매개 변수 데이터 세트를 생성합니다. 인공 신경망 설계에서 전통적인 기계 학습 알고리즘 설계의 주요 차이점은 신경망이 출력 계층을 통해서만 손실 기능과 상호 작용한다는 것이다. 따라서, 출력 레이어와 손실 기능이 당면한 작업에 따라 함께 설계되는 것은 매우 합리적이다. 자율주행에서 보통 마주치는 주요 인식 작업을 더 깊이 파고들자. 자율주행 인식에 사용하는 첫 번째 중요한 과제는 분류이다. 분류는 입력 x를 취하고 k 클래스나 카테고리 중 하나에 매핑하는 것으로 설명될 수 있다. 예를 들어, 이미지를 특정 범주에 매핑하려는 이미지 분류, 예를 들어 고양이나 개가 포함되어 있는지 여부와 이미지의 모든 픽셀을 카테고리에 매핑하려는 의미론적 세분화가 있습니다. 우리가 보통 자율주행 인식에 사용하는 두 번째 작업은 회귀이다. 회귀에서, 우리는 입력을 실수 집합에 매핑하고 싶습니다. 회귀의 예로는 이미지의 모든 픽셀에 대한 실제 깊이 값을 추정하려는 깊이 추정이 있습니다. 우리는 또한 두 과제를 함께 섞을 수 있다. 예를 들어, 객체 탐지는 일반적으로 객체가 포함된 경계 상자와 경계 상자에 있는 객체 유형을 식별하는 분류 작업을 추정하는 회귀 작업으로 구성됩니다. 이제 이러한 기본 인식 작업 각각과 관련된 출력 계층 손실 함수 쌍을 설명할 것입니다. 먼저 분류 작업부터 시작하겠습니다. 보통, k 클래스 분류 작업의 경우, 우리는 softmax 출력 레이어를 사용합니다. 소프트맥스 출력 레이어는 k 클래스에 대한 확률 분포를 나타낼 수 있다. 소프트맥스 출력 레이어는 신경망의 마지막 숨겨진 레이어의 출력인 입력 h로 취한다. 그런 다음 아핀 변환을 통해 변환된 출력 벡터 z를 생성합니다. 다음으로, 벡터 z는 softmax 요소별 함수를 사용하여 이산 확률 분포로 변환됩니다. 각 요소 z_i에 대해, 이 함수는 z의 모든 요소의 지수 합에 대한 요소 z_i의 지수 비율을 계산한다. 결과는 0과 1 사이의 값이며 이 모든 요소의 합은 하나이며, 적절한 확률 분포이다. Softmax 출력 레이어를 더 잘 설명하기 위해 숫자 예를 살펴보겠습니다. 이 예에서는 고양이, 개 또는 여우가 포함된 이미지를 분류하고 싶습니다. 먼저 우리는 네트워크에 따라 이미지가 고양이일 확률에 대응하도록 출력 벡터의 첫 번째 요소를 정의합니다. 클래스의 순서는 임의적이며 네트워크 성능에 영향을 미치지 않습니다. 아핀 변환의 출력을 취하여 출력의 각 요소의 지수를 모든 요소의 지수 합으로 나누어 확률을 계산합니다. 선형 변환 층의 출력으로 13 마이너스 7 및 11의 값을 감안할 때, 우리는 이 이미지가 고양이일 확률이 88%, 이 이미지가 여우이고 이 이미지가 개일 확률이 매우 낮습니다. 이제, 우리의 추정치가 얼마나 정확한지 보여주기 위해 softmax 출력 레이어의 출력을 사용하는 손실 함수를 설계하는 방법을 봅시다. Softmax 출력 레이어와 함께 사용할 표준 손실 함수는 softmax 함수의 음수 로그를 사용하여 형성되는 Cross-Entropy Loss입니다. 교차 엔트로피 손실에는 네트워크의 출력이 실제 확률에 얼마나 가까운지 제어하는 두 가지 용어가 있다. Z_i는 softmax 함수를 통과하기 전에 true 클래스에 해당하는 숨겨진 레이어의 출력이다. 이것은 보통 로지스틱 회귀 분야에서 나오는 클래스 로지트라고 불린다. 이 손실 함수를 최소화할 때, 클래스 logit z_i의 음수는 네트워크가 올바른 클래스의 확률에 대해 큰 값을 출력하도록 장려한다. 반면에 두 번째 용어는 아핀 변환의 생산량이 작도록 장려한다. 두 용어는 네트워크가 예측된 클래스 확률과 실제 클래스 확률의 차이를 최소화하도록 장려한다. 이 손실을 더 잘 이해하기 위해. 교차 엔트로피 손실이 분류 신경망의 출력에서 어떻게 계산되는지에 대한 수치적 예를 살펴보겠습니다. 이전 예시를 재검토하면서, 우리는 먼저 z 서브 i가 무엇인지 선택해야 합니다. Z 서브 i는 진정한 입력 클래스에 해당하는 선형 변환 출력이다. 이 경우, z_i는 cat 클래스에 해당하는 선형 변환 출력 요소이다. Z 하위 i를 결정하면, 교차 엔트로피를 사용하여 최종 손실 값을 계산합니다. 이 경우, 네트워크는 입력이 고양이임을 올바르게 예측하고 0.12의 손실 함수 값을 본다. 이제 잘못된 네트워크 출력으로 계산을 다시 합시다. 네트워크에 대한 입력은 여전히 고양이 이미지이다. 네트워크는 여전히 선형 변환 출력의 고양이 항목에 13의 값을 할당한다. 하지만 이번에는 여우 항목은 14의 값을 얻을 것이다. 교차 엔트로피 손실을 계산하면 이전 슬라이드의 값의 10배 이상 1.31로 평가된다는 것을 발견했습니다. 손실 함수가 출력의 차이가 하나일 때에도 잘못된 예측에 얼마나 큰 불이익을 주는지 주목하세요. 이러한 차이는 학습 과정을 가속화하고 교육 중에 네트워크 출력을 진정한 가치로 빠르게 조정합니다. 지금까지 우리는 분류 작업과 관련된 출력 계층과 손실 함수를 제시했습니다. 이제 회귀 작업을 위한 가장 일반적인 출력 계층을 살펴보겠습니다. 선형 출력 계층은 주로 공통 확률 분포의 통계를 모델링하는 회귀 작업에 사용된다. 선형 출력 계층은 단순히 비선형성 없이 단일 아핀 변환으로 구성되어 있다. 선형 출력 레이어로 모델링할 통계는 우리가 선택한 손실 함수에 따라 다릅니다. 예를 들어, 확률 분포의 평균을 모델링하기 위해, 우리는 평균 제곱 오류를 손실 함수로 사용합니다. 위에서 설명한 선형 및 소프트맥스 출력 장치는 오늘날 신경망에서 사용되는 가장 일반적인 출력 계층이며 자율주행을 위한 다양한 유용한 인식 작업을 수행하기 위해 다양한 작업별 손실 기능과 결합될 수 있습니다. 다른 많은 출력 계층과 손실 기능이 존재하며 이것은 딥 러닝에서 활발한 연구 영역으로 남아있다. 이 수업에서는 기계 학습 모델을 구축하려면 네트워크 모델, 손실 기능 및 네트워크 매개 변수를 배우기 위한 최적화 절차를 정의해야 한다는 것을 배웠습니다. 또한 신경망 모델이 수행해야 하는 작업에 따라 어떤 손실 기능을 선택해야 하는지 배웁니다. 다음 비디오에서, 우리는 신경망 설계 프로세스의 최종 구성 요소에 대해 논의할 것입니다; 특정 작업에 가장 적합한 매개 변수 세트 데이터를 얻는 방법을 포함하는 최적화. 다음에 보자.