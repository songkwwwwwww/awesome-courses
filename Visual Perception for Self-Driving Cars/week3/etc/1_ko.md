[음악] [소리] [음악] 안녕하세요 그리고 코스의 3주차에 오신 것을 환영합니다. 이번 주에, 당신은 자율 인식, 인공 신경망에 대해 생각하는 방식을 바꾼 주제에 대해 배우게 될 것입니다. 이 모듈을 통해 이러한 알고리즘을 사용하여 자율주행 자동차 인식 스택을 구축하는 방법을 배우게 되며, 심층 신경망을 설계하고 훈련시키는 다양한 구성 요소를 배우게 됩니다. 이제 인공 신경망에 대해 알아야 할 모든 것을 가르칠 수는 없지만, 이 모듈은 이 분야에 대한 좋은 소개입니다. 인공 신경망이 관심 있는 주제라면, Coursera에서 제공되는 딥 러닝 및 기계 학습 과정을 자유롭게 확인하세요. 이 수업에서는 매우 유용한 기본 유형의 인공 신경망인 피드포워드 신경망의 구성 요소에 대해 배우게 됩니다. 특히, 우리는 피드포워드 신경망의 숨겨진 층을 살펴볼 것이다. 숨겨진 계층은 신경망의 행동 방식을 나머지 기계 학습 알고리즘과 구별하기 때문에 중요하다. 피드포워드 신경망의 수학적 정의를 살펴보는 것으로 시작하겠습니다. 그래서 당신은 인식 스택을 위해 이러한 알고리즘을 구축하는 방법을 이해하기 시작할 수 있습니다. 피드포워드 신경망은 x와 세타의 함수 f를 통해 입력 x에서 출력 y로의 매핑을 정의한다. 예를 들어, 우리는 신경망을 사용하여 카메라 이미지의 모든 자동차의 위치와 같은 출력을 생성합니다. 함수 f는 입력 x를 취하고, 학습된 매개 변수 세타 세트를 사용하여 x와 상호 작용하여 출력 y를 생성합니다. 학습된 매개 변수의 개념은 입력을 출력에 직접 매핑하는 함수 f의 올바른 형태로 시작하지 않기 때문에 여기서 중요합니다. 대신, 우리는 일반적인 신경망을 사용하여 실제 기능에 대한 근사치를 구성해야 한다. 이것은 신경망이 기능 근사치로 생각할 수 있다는 것을 의미한다. 보통 우리는 피드포워드 신경망을 기능 구성으로 묘사한다. 어떤 의미에서, i의 각 함수 f는 이전 함수 위에 있는 레이어이며, i- 1의 f이다. 보통 우리는 N이 많은 숫자인 구성에 N 함수를 가지고 있으며, 향상된 표현을 위해 레이어 위에 층을 쌓는다. 이 레이어링은 이러한 함수 시퀀스를 설명하는 분야의 딥 러닝이라는 이름으로 이어졌다. 이제 이 기능 구성을 시각적으로 설명합시다. 여기서 4층 피드포워드 신경망을 볼 수 있습니다. 이 신경망에는 함수 근사치에 대한 데이터 입력 x를 설명하는 입력 계층이 있다. 여기서 x는 스칼라, 벡터, 매트릭스 또는 이미지와 같은 n차원 텐서가 될 수 있습니다. 입력은 신경망의 첫 번째 계층인 x의 함수 f1에 의해 처리된다. 우리는 이 레이어를 첫 번째 숨겨진 레이어라고 부른다. 마찬가지로, 두 번째 숨겨진 레이어는 x의 함수 f2를 통해 첫 번째 숨겨진 레이어의 출력을 처리합니다. 원하는 만큼 숨겨진 레이어를 추가할 수 있지만, 각 레이어는 배울 추가 매개 변수와 런타임에 수행할 더 많은 계산을 추가합니다. 우리는 나중에 숨겨진 레이어의 수가 우리 시스템의 성능에 어떤 영향을 미치는지 논의할 것이다. 신경망의 최종 계층은 출력 계층이라고 불린다. 마지막 숨겨진 레이어의 출력을 가져와 원하는 출력 Y로 변환합니다. 이제, 우리는 왜 이 네트워크들이 피드포워드라고 불리는지에 대한 직감을 가져야 한다. 이것은 정보가 입력 x에서 몇 가지 중간 단계를 거쳐 피드백 연결 없이 출력 Y까지 흐르기 때문입니다. 이 용어는 자율주행 자동차에 대한 통제를 설명할 때 코스 1에서 사용하는 것과 같은 방식으로 사용됩니다. 이제 네트워크 정의로 돌아가서 시각적 표현이 함수 구성과 어떻게 일치하는지 확인해 봅시다. 이 표현식에서 우리는 입력 레이어라고 불리는 x를 본다. 우리는 출력 레이어인 가장 바깥쪽 함수 f 서브 N을 본다. 그리고 우리는 숨겨진 레이어인 f1에서 f N-1 사이의 각 함수를 본다. 이제 이러한 매혹적인 기능 근사치를 더 깊이 탐구하기 전에 자율주행에 어떻게 사용할 수 있는지에 대한 몇 가지 예를 살펴보겠습니다. 기억하세요, 이 과정은 시각적 인식에 관한 것이므로, 우리는 입력 x를 항상 이미지로 제한할 것입니다. 가장 기본적인 인식 작업은 분류 작업이다. 여기서 우리는 신경망이 라벨을 통해 이미지에 무엇이 있는지 알려주도록 요구한다. 우리는 장면의 물체에 대한 라벨뿐만 아니라 위치를 추정함으로써 이 작업을 더 복잡하게 만들 수 있다. 이것은 물체 감지라고 불린다. 우리가 관심을 가질 수 있는 또 다른 작업 세트는 픽셀별 작업이다. 예를 들어 이미지의 모든 픽셀에 대한 깊이 값을 추정할 수 있습니다. 이것은 우리가 물체가 어디에 있는지 결정하는 데 도움이 될 것이다. 또는 각 픽셀이 어떤 클래스에 속하는지 결정하고 싶을 수도 있습니다. 이 작업은 의미론적 세분화라고 불리며, 우리는 과정의 뒷부분에서 물체 감지와 함께 이것을 깊이 논의할 것입니다. 각각의 경우, 우리는 신경망을 사용하여 매핑이 어떻게 작동하는지 명시적으로 모델링하지 않고도 이미지에서 생성하려는 인식 출력에 이르기까지 원시 픽셀 값 사이의 복잡한 매핑을 배울 수 있습니다. 모델화하기 어려운 프로세스를 나타내는 이러한 유연성은 신경망을 매우 인기 있게 만드는 것이다. 이제 강력한 인식 모델을 만드는 데 필요한 매개 변수를 배우는 방법을 살펴보겠습니다. 신경망 훈련이라고 불리는 과정에서, 우리는 네트워크를 설명하는 매개 변수 세타를 수정하여 (x)의 신경망 함수 f와 세타를 실제 함수 f*(x)와 일치시킵니다. 세타의 수정은 입력 x의 네트워크 쌍과 그에 상응하는 true 출력 f*(x)를 제공함으로써 수행됩니다. 그런 다음 실제 출력을 네트워크에서 생성된 출력과 비교하고 네트워크 매개 변수를 최적화하여 출력 오류를 줄일 수 있습니다. 각 예제에 대해 신경망의 출력만 지정되기 때문에, 훈련 데이터는 네트워크가 숨겨진 계층으로 무엇을 해야 하는지 지정하지 않는다. 네트워크 자체는 f*(x)의 근사치를 가장 잘 구현하기 위해 이러한 레이어를 수정하는 방법을 결정해야 합니다. 사실, 숨겨진 단위는 다른 기계 학습 모델과 비교할 때 신경망을 독특하게 만드는 것이다. 그래서 숨겨진 레이어 구조를 더 명확하게 정의합시다. 숨겨진 레이어는 아핀 변환과 요소 현명한 비선형 함수 g로 구성되어 있다. 이 비선형 함수는 활성화 함수라고 불린다. N번째 숨겨진 레이어에 대한 입력은 n- 1의 h이며, 이전 숨겨진 레이어의 출력이다. 레이어가 첫 번째 숨겨진 레이어인 경우, 입력은 단순히 입력 이미지 x입니다. 아핀 변환은 곱셈 가중 행렬 W와 첨가제 편향 행렬 B로 구성되어 있다. 이러한 가중치와 편향은 신경망의 정의에서 학습 매개 변수 세타이다. 마지막으로, 변환된 입력은 활성화 함수 g를 통과한다. 대부분의 경우, g는 네트워크에서 배울 매개 변수를 포함하지 않는다. 예를 들어, 오늘날 대부분의 신경망에서 활성화 함수의 기본 선택인 정류된 선형 단위 또는 ReLU를 살펴보겠습니다. ReLU는 0 사이의 최대값과 아핀 변환의 출력을 요소별 비선형 함수로 사용합니다. 그것들은 선형 단위와 매우 유사하기 때문에 최적화하기가 매우 쉽다. ReLU 숨겨진 계층 계산의 예를 살펴보겠습니다. 이전 숨겨진 레이어 hn- 1, 가중치 행렬 W 및 바이어스 행렬 b의 출력이 주어집니다. 우리는 먼저 아핀 변환을 평가해야 한다. 무게 매트릭스는 계산에서 전치된다는 것을 기억하세요. 이 표현식에서 각 행렬의 크기를 살펴보겠습니다. hn- 1은 이 경우 2x3 행렬입니다. W는 2x5 매트릭스이다. 우리의 아핀 변환의 최종 결과는 5x3 매트릭스이다. 이제, 이 매트릭스를 ReLU 비선형으로 통과합시다. 우리는 ReLU가 아핀 변환의 음수 출력이 다음 레이어로 통과하는 것을 방지한다는 것을 알 수 있다. 신경망의 숨겨진 계층에서 요소 현명한 비선형성으로 사용할 수 있는 많은 추가 활성화 기능이 있습니다. 사실, 숨겨진 단위의 설계는 현장에서 또 다른 매우 활발한 연구 분야이며 아직 많은 지침 이론적 원리가 없다. 예를 들어, 특정 신경망 아키텍처는 시그모이드 비선형성, 쌍곡선 접선 비선형성, 최대 비선형성인 ReLU의 일반화를 숨겨진 레이어 활성화 기능으로 사용합니다. 신경망 아키텍처에 대해 더 알고 싶다면, Coursera에서 제공되는 딥 러닝 과정을 확인하는 것이 좋습니다. 그들은 놀라워. 이 수업에서, 당신은 우리가 사용하는 기계 학습 모델의 핵심을 구성하는 숨겨진 레이어를 포함한 피드포워드 신경망의 주요 구성 요소를 배웠습니다. 또한 ReLU가 이 분야의 많은 실무자들에게 기본 선택인 다양한 유형의 활성화 기능을 배웠습니다. 다음 수업에서는 출력 레이어를 탐색한 다음 훈련 데이터에서 가중치와 편향 행렬을 배우는 방법을 연구하여 나중에 모듈에서 첫 번째 신경망을 훈련하기 위한 단계를 설정할 것입니다. [음악]