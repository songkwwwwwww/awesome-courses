안녕하세요, 물체 감지 모듈의 마지막 수업에 오신 것을 환영합니다. 지금까지, 우리는 2D 물체 감지를 수행하는 방법을 설명했습니다. 그러나, 우리는 여전히 2D 물체 감지가 자율주행 자동차에 유용한 이유에 대해 논의해야 한다. 이 수업에서는 2D 물체 감지를 수행해야 하는 세 가지 중요한 응용 프로그램에 대해 논의할 것입니다. 먼저, 우리는 2D 물체 탐지기를 3D로 확장하는 방법에 대해 논의할 것입니다. 둘째, 우리는 도로에서 다른 에이전트의 행동을 모델링하기 위한 물체 추적과 중요한 도구에 대해 논의할 것이다. 마지막으로, 우리는 2D 물체 감지의 개념을 교통 표지판과 신호 감지에 적용하는 방법에 대해 논의할 것입니다. 자율주행 자동차는 환경을 안전하게 통과할 수 있도록 3D로 현장 이해가 필요하다. 보행자, 자동차, 차선 및 표지판이 차 주변에 어디에 있는지 아는 것은 자율적일 때 안전하게 취할 수 있는 행동을 완전히 정의한다. 이것은 이미지 평면에서 물체를 감지하는 것만으로는 충분하지 않다는 것을 의미합니다. 우리는 문제를 2D에서 3D로 확장하고, 세계 프레임에서 감지된 물체를 찾아야 한다. ConvNets를 사용한 3D 객체 감지는 비교적 새로운 주제이며, 이 도메인의 결과는 끊임없이 변화하고 있다. 2D 대응과 마찬가지로, 3D 물체 감지는 카테고리 분류가 필요합니다. 예를 들어, 이것은 자동차가 보행자와 다르게 움직이기 때문에 물체를 추적하는 데 필수적이므로, 객체 클래스가 알려진 경우 더 나은 예측이 가능합니다. 또한, 우리는 3D로 중심적인 물체의 위치, 3D의 범위, 3D의 방향을 추정하고 싶습니다. 각각의 경우에, 이 상세한 상태 정보는 움직임 예측과 충돌 회피를 개선하고, 자동차 교통 체증 이동 능력을 향상시킵니다. 이 객체의 상태는 객체의 x, y, y 위치로 표현된 중심 위치의 3D 벡터로 표현될 수 있다. 물체의 길이, 너비 및 높이로 표현되는 확장용 3D 벡터. 물체의 롤, 피치 및 요우 각도로 표현되는 방향 각도의 3D 벡터. 도로 장면의 경우, 대부분의 도로 요원이 지상 표면이 지시하는 것 이상으로 롤과 피치 각도를 변경할 수 없기 때문에 우리가 관심 있는 방향 각도는 보통 요 각도일 뿐입니다. 따라서 요 각도만 추적하는 것으로 충분하다. 하지만 2D 경계 상자에서 물체의 위치와 범위에 대한 정확한 3D 추정으로 어떻게 얻을 수 있을까요? 3D로 2D 물체 감지 결과를 확장하는 가장 일반적이고 성공적인 방법은 LiDAR 포인트 클라우드를 사용하는 것입니다. 이미지 공간의 2D 경계 상자와 3D LiDAR 포인트 클라우드가 주어지면, 카메라 프로젝션 매트릭스의 역을 사용하여 경계 상자의 모서리를 3D 공간에 광선으로 투사할 수 있습니다. 이 선의 다각형 교차점은 프루스텀이라고 불리며, 보통 우리 이미지의 물체에 해당하는 3D 지점을 포함한다. 그런 다음 LiDAR에서 이 프러스텀의 데이터를 가져다가, 우리가 선택한 표현으로 변환하고, 작은 신경망을 훈련시켜 경계 상자를 3D로 정의하는 데 필요한 일곱 가지 매개 변수를 예측합니다. 이제, 프루섬에서 LiDAR 지점의 어떤 표현을 신경망에 입력해야 할까요? 일부 그룹은 원시 포인트 클라우드 데이터를 직접 처리하기로 선택합니다. 다른 사람들은 프루텀 센터와 같은 고정점과 관련하여 포인트 클라우드 데이터를 정규화하기로 선택합니다. 마지막으로, 예를 들어, x, y, z의 히스토그램과 같은 고정 길이 표현을 구축하기 위해 포인트를 전처리하여 대륙에 대한 입력으로 훨씬 더 편리하게 사용할 수 있습니다. 우리가 어떤 표현을 사용하든, 우리는 지향적인 3D 경계 상자의 형태로 결과를 얻을 것으로 예상된다. 위에서 논의한 절차는 3D 물체 감지를 수행하는 한 가지 방법일 뿐이라는 것을 명심하세요. 그렇다면, 왜 우리는 3D로 직접 물체를 감지하기보다는 2D 감지를 3D로 확장하기로 선택해야 할까요? 첫째, 2D 물체 탐지기는 3D 물체 검출기보다 훨씬 더 잘 정립되어 있다. 우리는 보통 매우 높은 정밀도를 얻고 성숙한 2D 물체 검출기에서 리콜할 수 있습니다. 3D 물체 감지 문헌에서 작업할 때 여전히 사용할 수 없는 것. 둘째, 우리는 2D 물체 탐지기 결과에서 무료로 분류를 받는다. 자동차나 게시물을 보고 있는지 결정하기 위해 LiDAR 데이터를 사용하거나 네트워크에 3D 정보를 전달할 필요가 없습니다. 이것은 이미지 데이터에서 2D로 눈에 띄게 보인다. 마지막으로, 물체를 어디에서 찾아야 하는지에 대한 가정이 없다면 가능한 물체를 3D 공간을 검색하는 것은 계산적으로 매우 비싸다. 2D 객체 탐지기를 3D로 확장하면 일반적으로 실시간 성능을 관리할 수 있도록 개체 인스턴스의 검색 영역을 제한할 수 있습니다. 그러나, 2D 객체 탐지기를 3D로 확장하면 일련의 독특한 문제가 발생한다. 3D 물체 감지에 이 접근 방식을 사용함으로써 발생하는 한 가지 두드러진 문제는 3D 포즈 추정기의 성능을 2D 검출기의 성능인 상한선으로 결합했다는 것이다. 게다가, 2D에서 3D 방법은 일반적으로 LiDAR 데이터에 영향을 미치지 않을 수 있는 카메라 관점에서 심각한 폐색과 절단에 직면할 때 실패합니다. 마지막으로, 이 접근법의 연속적인 특성에 의해 유도된 대기 시간은 보통 무시할 수 없다. 지연은 지연된 인식으로 나타나며, 이는 우리 차가 특정 지연 후 도로에서 물체를 볼 수 있다는 것을 의미합니다. 이 지연이 중요하다면, 차량 반응 시간이 인식 지연에 의해 제한되기 때문에 시스템이 작동하기에 충분히 안전하지 않을 수 있습니다. 2D에서 3D 물체 감지의 또 다른 매우 중요한 응용 프로그램은 물체 추적이다. 추적은 시간이 지남에 따라 물체의 움직임을 정의하는 트랙에 동일한 물체의 일련의 탐지를 결합하는 것을 포함한다. 우리는 2D와 3D 모두에서 사용할 수 있는 간단한 추적 방법을 설명하는 것으로 시작할 것이며, 이는 코스 2에서 친숙하게 들리기를 바랍니다. 물체 감지를 수행할 때, 우리는 보통 각 프레임에서 물체를 독립적으로 감지합니다. 그러나 추적에서, 우리는 일반적으로 알려진 객체 동적 모델을 통해 예측된 위치를 통합합니다. 추적에는 장면이 얼마나 빨리 바뀌는지 제한하는 일련의 가정이 필요합니다. 예를 들어, 우리는 카메라와 추적된 물체가 매우 짧은 시간 내에 다른 위치로 순간이동할 수 없다고 가정합니다. 또한, 우리는 그 장면이 매끄럽고 점진적으로 변한다고 가정한다. 이러한 모든 가정은 도로 장면에서 논리적으로 유효하다. 물체 추적이 어떻게 생겼는지 시각적으로 봅시다. 속도 벡터와 함께 첫 번째 프레임에서 감지된 물체를 감안할 때, 우리는 물체가 두 번째 프레임에서 어디로 끝날지 예측하는 것으로 시작합니다. 속도 벡터를 사용하여 움직임을 모델링하면 두 번째 프레임에서 새로운 감지를 얻습니다. 우리는 이러한 감지 또는 측정을 호출하고, 각 탐지를 해당 측정과 연관시킨 다음, 상관 측정을 사용하여 물체 예측을 업데이트합니다. 필요한 각 단계를 설명합시다. 첫째, 우리는 블록 상태를 이미지 공간의 위치와 속도로 정의합니다. 각 객체에는 상태를 업데이트하는 모션 모델이 있습니다. 예를 들어, 여기에 표시된 일정한 속도 모션 모델은 각 경계 상자를 두 번째 프레임의 새로운 위치로 이동하는 데 사용됩니다. 모델이 완벽하지 않기 때문에 모션 모델에 제로 평균 가우스 노이즈를 추가했습니다. 예측 단계 후, 우리는 2D 물체 검출기에서 두 번째 프레임 측정을 얻습니다. 그런 다음 모든 예측과 모든 측정 간의 IOU를 계산하여 각 측정을 예측과 연관시킵니다. 측정은 그 예측에서 가장 높은 IOU를 가지고 있다면 해당 예측과 상관관계가 있다. 마지막 단계는 Kalman 필터를 사용하여 측정 및 예측 업데이트를 융합하는 것으로 구성됩니다. 이 단계가 어떻게 수행되는지 기억하기 위해 코스 2에 제시된 칼만 필터 방정식을 검토하는 것이 좋습니다. 칼만 필터는 위치와 속도를 포함한 전체 객체 상태를 업데이트하며, 후속 예측 단계에서 사용할 수 있습니다. 물체 크기를 추적할 필요는 없지만 대신 탐지기에 의존할 수 있습니다. 우리는 보통 물체를 마지막으로 알려진 측정의 크기로 할당한다. 몇 가지 복잡성, 특히 트랙을 시작하는 방법과 종료하는 방법에 대해 다루어야 한다. 이전 예측과 관련이 없는 2D 검출기 결과를 얻으면 새로운 트랙을 시작합니다. 마찬가지로, 예측된 물체가 미리 설정된 수의 프레임에 대한 측정과 관련이 없다면 일관성 없는 트랙을 종료합니다. 마지막으로, 3D로 IOU를 정의함으로써 3D 객체 추적에 동일한 방법론을 사용할 수 있다는 점에 유의해야 합니다. 자율주행차 3D 물체 추적의 비디오를 살펴봅시다. 감지에는 프레임 위치 추정치를 프레임하기 위해 프레임에 약간의 소음이 있기 때문에 트랙은 약간 불안하며, 이 코드에 사용된 모션 모델에는 정확한 차량 운동학 또는 동적 모델이 포함되어 있지 않습니다. 이것은 다른 차량 스티어링 및 가속 입력에 대한 지식이 부족하기 때문입니다. 그럼에도 불구하고, 우리는 여전히 환경을 통과하는 여러 차량을 정확하게 감지하고 우선 순위와 안전한 상호 작용에 대해 신중한 결정을 내릴 수 있습니다. 우리가 2D 물체 감지의 틀 내에서 설명할 마지막 개념은 교통 표지판과 교통 신호를 감지하는 것이다. 이러한 도로 규칙 지표의 올바른 탐지는 자율주행 자동차를 바쁜 거리에서 합법적으로 운전할 때 안내한다. 그러나, 탐지 작업은 별도의 도전을 초래한다. 가장 눈에 띄는 것들을 살펴보자. 여기서 자율주행 자동차에 장착된 카메라에서 전형적인 대시 캠 스타일 이미지를 볼 수 있습니다. 보통, 자동차가 적시에 적절하게 반응하는 방법을 알기 위해 장거리에서 교통 신호가 감지되어야 한다. 장거리에서 교통 신호와 신호는 이미지에서 매우 적은 수의 픽셀을 차지하여 감지 문제를 특히 어렵게 만든다. 게다가, 교통 표지판은 매우 다양하다. 보통, 안정적으로 분류되어야 하는 최대 50개의 수업을 포함한다. 반면에 신호등은 세계의 다른 지역에서 다르게 나타날 수 있으며, 자율주행 자동차가 신호가 있는 교차로를 통해 안전하게 기동하기 위해 감지해야 하는 여러 상태를 가지고 있다. 게다가, 차가 움직일 때 신호등이 상태를 바꾼다. 이것은 이미지 공간에서 교통 신호를 추적하려고 할 때 몇 가지 문제를 일으킬 수 있습니다. 신호등이 있는 주와 관련하여 모양이 변함에 따라. 다행히도, 우리가 지금까지 설명한 표준 물체 탐지기는 교통 신호와 신호를 감지하기 위해 큰 수정 없이 사용될 수 있다. 그러나, 현재의 접근 방식은 이 탐지 작업을 더 강력하게 수행하기 위해 다단계 계층적 모델에 의존한다. 여기에 표시된 2단계 모델을 고려해 봅시다. 두 단계는 각 작업을 수행하기 위해 기능 추출기의 출력을 공유합니다. 이 예에서, 첫 번째 단계는 각 상자가 속한 클래스를 지정하지 않고 이미지의 모든 트래픽 기호와 신호를 가리키는 클래스 불가지론적 경계 상자를 출력합니다. 그런 다음 두 번째 단계는 첫 번째 단계에서 모든 경계 상자를 가져와 빨간색, 노란색 또는 녹색 신호 정지 신호 등과 같은 범주로 분류합니다. 또한, 일부 방법은 두 번째 단계를 사용하여 첫 번째 단계에서 제공된 경계 상자를 더욱 구체화합니다. 이 다단계 접근 방식은 교통 표지판과 신호에만 국한되지 않으며, 많은 일반적인 물체 감지 프레임워크는 정확한 객체 클래스와 위치를 생성하기 위해 다단계 방법을 사용합니다. 관심이 있다면, 우리는 이러한 접근 방식 중 일부를 보충 독서 자료로 제공했습니다. 이 비디오에서, 우리는 2D 물체 검출기의 출력을 사용하여 3D 물체 위치를 생성하는 데 사용될 수 있다는 것을 보았고, 연속적인 이미지 프레임에서 2D 물체 검출기 출력에서 추적을 수행하여 환경을 통해 개체 트랙을 만드는 방법을 연구했으며, 2D 물체 탐지기를 사용하여 주요 수정 없이 교통 신호와 교통 신호를 감지할 수 있는 방법을 탐구했습니다. 그러나, 계층적 모델을 활용하는 특수 방법은 보통 표준 방법보다 더 잘 수행한다. 우리는 이제 자율주행 자동차에 사용되는 주요 유형의 물체 감지에 필요한 도구를 가지고 있습니다. 축하해. 2D 물체 감지에 대한 이 모듈을 성공적으로 완료했습니다. 이 모듈은 상당히 관련되어 있으며 2D 및 3D 물체 감지 및 추적을 위해 신경망을 사용하는 방법에 대한 자세한 내용은 제공된 리소스를 확인하는 것이 좋습니다. 다음 주에, 우리는 픽셀 수준에서 작동하는 시각적 인식 스택의 또 다른 중요한 구성 요소인 의미론적 세분화에 대해 논의할 것입니다. 그때 보자.