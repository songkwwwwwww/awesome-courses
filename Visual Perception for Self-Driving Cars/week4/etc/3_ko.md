[음악] 마지막 수업에서 우리는 편리함을 사용하여 물체 감지를 수행하기 위한 기본 접근 방식을 배웠다. 그러나 앵커 그리드의 모든 앵커를 처리하면 개체당 예상되는 단일 잠금이 아닌 개체당 여러 경계 상자가 감지되었습니다. 이 수업에서는 2D 물체 감지를 위한 컨볼루션 신경망을 구축하고 훈련시키는 데 필요한 최종 구성 요소에 대해 논의할 것입니다. 특히, 미니 배치 선택을 통해 훈련하는 동안 그리고 비최대 억제를 통해 추론 중에 물체당 여러 개의 회귀된 앵커를 처리하는 방법을 배우게 될 것입니다. 신경망 훈련을 검토하는 것으로 시작합시다. 우리는 cond net 모델과 훈련 데이터 쌍, x, 입력 이미지, f star of x, 경계 상자 위치 및 클래스가 제공됩니다. 우리는 출력 경계 상자 y가 x와 세타의 f와 같은 x의 f 별을 근사하고 싶습니다. 지난 주부터 예측된 경계 상자가 지상 진실 경계 상자와 얼마나 유사한지 측정하는 손실 함수를 먼저 평가하여 훈련을 수행했다는 것을 상기하십시오. 그런 다음 결과 손실 함수를 두 번째 반복에 사용할 새로운 매개 변수 세타 세트를 출력하는 옵티마이저에 공급합니다. 기능 추출기와 출력 레이어가 모두 훈련 중에 수정된다는 것을 주목하세요. 이제 x 세타의 x와 f의 f 별이 일대일이라면, 우리의 문제는 쉬웠을 것이다. 그러나, 우리 네트워크의 출력은 단일 지상 진실 상자와 연관될 수 있는 여러 상자이다. 이 문제를 해결하기 위해 우리가 어떻게 노력할 수 있는지 봅시다. 기능 맵의 각 픽셀에 대해 k 앵커를 연결한다는 것을 기억하십시오. 원본 이미지에서 이 앵커들은 어디에 나타나나요? 앞서 배웠듯이, 우리의 기능 추출기는 초기 입력의 해상도를 32배 줄입니다. 즉, 기능 맵의 모든 픽셀을 앵커 세트와 연결하면 이러한 앵커를 보폭 32가 있는 그리드에 배치하여 초기 이미지로 전송됩니다. 그런 다음 우리는 이 앵커와 함께 지상 진실 경계 상자를 시각화할 수 있다. 일부 앵커가 겹치고 일부는 그렇지 않다는 것을 알 수 있습니다. 우리는 이 중복을 IOU와 정량화하고 앵커를 두 가지 범주로 분류합니다. 먼저 두 개의 IOU 임계값, 양의 앵커 임계값 및 음의 앵커 임계값을 지정합니다. IOU가 포지티브 앵커 임계값보다 큰 앵커는 포지티브 앵커라고 불린다. 그리고 마찬가지로, IOU가 음의 앵커 임계값보다 작은 앵커는 음수 앵커라고 불린다. 두 임계값 사이에 IOU가 있는 앵커는 완전히 폐기됩니다. 그래서 이제, 우리는 훈련에서 이 긍정적이고 부정적인 앵커를 어떻게 사용하나요? 이제 양수 및 음수 앵커에 대한 분류 및 회귀 목표를 할당하는 방법을 살펴보겠습니다. 분류를 위해, 우리는 신경망이 부정적인 앵커가 백그라운드 클래스에 속한다고 예측하기를 원한다. 배경은 보통 이 수업에 포함되지 않은 것을 설명하기 위해 관심 있는 수업에 추가하는 수업이다. 반면에, 우리는 신경망이 지상 진실과 교차하는 긍정적인 앵커에 지상 진실 클래스를 할당하기를 원한다. 회귀를 위해, 우리는 양의 앵커의 매개 변수를 지상 진실 경계 상자의 매개 변수와 일치하도록 바꾸고 싶습니다. 음의 앵커가 배경이라고 가정하기 때문에 경계 상자 회귀에 사용되지 않습니다. 훈련 중에 여러 개의 회귀된 앵커를 처리하는 이러한 접근 방식은 문제에서 자유롭지 않다. 제안된 IOU 임계값 메커니즘은 대부분의 회귀된 앵커가 부정적인 앵커로 이어진다. 이 모든 앵커로 훈련할 때, 네트워크는 부정적인 클래스로 편향되는 긍정적인 예보다 훨씬 더 부정적인 것을 관찰할 것이다. 이 문제에 대한 해결책은 실제로 매우 간단하며, 손실된 함수를 계산하기 위해 모든 앵커를 사용하는 대신, 우리는 음수와 양의 앵커를 3대 1 비율로 선택한 미니배치 크기를 샘플링합니다. 네거티브는 온라인 하드 네거티브 마이너스 마이닝이라는 프로세스를 통해 선택되며, 마이너스 멤버는 분류 손실이 가장 높은 네거티브 앵커로 선택됩니다. 이것은 우리가 부정적인 분류에서 가장 큰 오류를 해결하기 위한 훈련을 받았다는 것을 의미한다. 예를 들어, 64개의 예제의 미니배치가 있다면, 네거티브 미니배치는 분류 손실이 가장 높은 48개의 네거티브 예가 될 것이며, 나머지 16개의 앵커가 포지티브 앵커가 될 것이다. 양성자 수가 16개 미만인 경우, 일부 양성을 복사하여 미니배치를 패딩하거나 나머지 지점을 음의 앵커로 채웁니다. 지난 주 초에 설명했듯이, 우리는 ConvNet의 분류 책임자를 위해 교차 엔트로피 손실 함수를 사용했습니다. 총 분류 손실은 미니배치의 모든 앵커가 교차 엔트로피 손실의 평균이다. 정규화 상수와 합계는 선택된 미니배치 크기이다. Si는 분류 헤드의 출력이다. 그리고 Si 별은 부정적인 앵커에 대한 배경과 긍정적인 앵커를 위한 지상 진실 경계 상자의 클래스로 설정된 지상 진실 분류이다. 회귀를 위해, 우리는 비슷한 방식으로 L2 표준 손실을 사용합니다. 그러나, 우리는 그것이 긍정적인 앵커인 경우에만 앵커를 수정하려고 시도한다. 이것은 L2 표준에서 승수 Pi로 수학적으로 표현된다. 앵커가 음수인 경우 0이고 앵커가 양수인 경우 1입니다. 정상화하기 위해, 우리는 양의 앵코의 수로 나뉘며, 상기시켜 드리자면, 바이 스타는 지상 진실 경계 상자 표현이며, 바이는 추정 경계 상자이다. 박스 매개 변수를 직접 추정하는 것이 아니라 적층 잔류 또는 곱셈 척도로 앵커 매개 변수를 수정한다는 것을 기억하십시오. 따라서 bi는 예상 잔류물로 구성되어야 한다. 이러한 손실 기능으로 배우기 위해 신경망에 무엇을 가르치려고 하는지 시각화합시다. 입력 이미지, 지상 진실 경계 상자 및 앵커 이전의 입력 앵커 세트를 감안할 때, 우리는 신경망에 앵커를 보라색 배경이나 파란색의 배경을 포함하는 것으로 분류하도록 가르치고 있습니다. 이것은 위에 정의된 교차 엔트로피 손실을 최소화함으로써 이루어진다. 그런 다음 우리는 신경망이 가장 가까운 지상 진실 경계 상자와 일치하는 방식으로 관심 클래스가 포함된 앵커만 이동하기를 원합니다. 이것은 위에 정의된 L2 표준 손실을 최소화함으로써 이루어진다. 지금까지는 훈련 중에 물체에 대한 여러 출력 상자를 처리하는 방법을 잘 이해해야 합니다. 하지만 추론 중에 실시간으로 신경망을 실행할 때 우리는 무엇을 하나요? 추론하는 동안, 우리는 긍정적이고 부정적인 앵커를 결정할 근거가 없으며 손실 기능을 평가하지 않는다는 것을 기억하십시오. 우리는 장면에서 객체당 단일 출력 상자를 원합니다. 다음은 비최대 억제가 작용할 때, 앵커 기반 뉴런 네트워크의 추론 출력을 개선하는 매우 강력한 접근 방식입니다. 비최대 억제는 입력으로 예측된 경계 박스 b의 목록을 취하며, 각 경계 블록은 클래스 출력 점수의 회귀 좌표로 구성됩니다. 그것은 또한 입력으로 우리가 ada라고 부를 미리 정의된 IOU 임계값이 필요하다. 그런 다음 알고리즘은 다음과 같이 진행되며, 먼저 출력 점수에 따라 목록 B의 경계 상자를 정렬합니다. 우리는 또한 출력 경계 상자를 보관하기 위해 빈 세트 D를 초기화합니다. 그런 다음 정렬된 상자 목록 B 표시줄에서 전체 요소를 반복합니다. For 루프 내부에서, 우리는 먼저 B 막대의 첫 번째 요소여야 하는 목록 B에서 가장 높은 점수를 가진 상자 B max를 결정합니다. 그런 다음 경계 상자 세트 D 막대에서 이 경계 상자를 제거하고 출력 세트 D에 추가합니다. 다음으로, 우리는 상자 B max가 있는 ada보다 큰 IOU를 가진 세트 B 바에 남아있는 모든 상자를 찾습니다. 이 상자들은 현재 최대 상자인 B max와 크게 겹친다. 이 조건을 충족하는 모든 상자는 목록 B 바에서 제거됩니다. 우리는 비어있을 때까지 목록 B 막대를 계속 반복한 다음, 목록 D를 반환합니다. D는 이제 객체당 단일 경계 상자를 포함한다. 비최대 억제 알고리즘이 실제로 어떻게 작동하는지 이해하기 위해 시각적 예를 살펴보겠습니다. 경계 상자 목록을 줄어든 순서로 분류했다고 가정해 봅시다. 우리는 또한 비최대 억제가 어떻게 작동하는지에 대한 더 나은 가시성을 위해 여기에 점수 목록을 명시적으로 보여줍니다. b max는 정렬된 목록 B 막대의 첫 번째 경계 상자가 될 것입니다. 그런 다음 각 경계 상자를 b max로 비교합니다. 이 경우, 하나의 상자인 B3만 b max를 가진 0이 아닌 IOU를 가지고 있다. 우리는 그 IOU를 계산하고 그것을 우리의 IOU 임계값 ada와 비교한다. 이 경우, IOU는 임계값 ada보다 크므로 목록 B 표시줄에서 상자 3을 제거합니다. 우리는 목록에 남아있는 다음으로 높은 점수에 대한 과정을 반복합니다. 다시 말하지만, 하나의 상자에만 b max, 상자 4가 있는 0이 아닌 IOU가 있습니다. IOU를 계산하고 임계값과 비교하면 목록 B 표시줄에서 상자 4를 제거하고 출력 목록 D에 상자 2를 추가합니다. 우리는 우리의 초기 목록인 B 바가 이제 비어 있다는 것을 알아차렸다. 따라서 우리의 비최대 억제 알고리즘은 예상대로 객체당 하나의 경계 상자를 포함하는 출력 상자 목록 D를 종료하고 반환합니다. 축하합니다, 이제 자율주행 자동차용 ConvNet 기반 2D 물체 탐지기를 훈련하고 배포하는 데 필요한 콘텐츠를 완료했습니다. 이 비디오에서는 클래스 균형을 유지하기 위해 훈련 중에 네트워크 출력을 조정하고 추론 중에 네트워크 출력을 제한하여 객체당 하나의 출력 경계 상자를 선택하는 방법을 살펴보았다. 다음 수업에서, 우리는 자율주행 자동차에 중요한 다양한 작업에 이러한 2D 물체 감지기의 출력을 어떻게 사용할 수 있는지 논의할 것입니다. 2D 물체 감지를 3D로 변환하고, 물체 움직임을 추적하고, 교통 신호에 2D 물체 감지를 적용하고, 신호 감지를 포함합니다. 거기서 보자. [음악]