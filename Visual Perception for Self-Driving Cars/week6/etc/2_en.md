In the last video, you were introduced to the final course assessment in which you will have to develop three major aspects of the procession stack of a self-driving car. This lesson, we will expose you to some algorithmic concepts that will be useful to finish this assessment. The first thing to be aware of while attempting the assignment, is the coordinate frames you are working in. All the required 3D estimation will be performed in the camera coordinate frame. That includes the ground plane, distance to impact, and other 3D quantities. However, the camera as a sensor is usually oriented with its y-axis pointing downward. What does that mean for you while working on the assessment? The only thing you will need to be careful about, is the sign of the height value of pixels. Points higher than the camera will have a negative height, while points lower than the camera will have a positive height. The second topic you should be aware of, is how to solve linear least squares problems for plane estimation in Python. For this part of the assessment, you will have a couple of alternatives. We provide you with a function that does the plane estimation for you using singular value decomposition or SVD for short. However, if you want to challenge, you could try solving the plane estimation problem yourself by solving the least squares problem using the NumPy native function lstsq. If you choose this path, be careful to choose more than three points for each iteration of RANSAC, as the solver might not provide any useful results in certain edge cases where the system is poorly conditioned. A greater challenge would be to implement SVD plane fitting from scratch. SVD almost always provides a numerically stable solution. In addition, it can be faster than the NumPy lstsq function. It's up to you which path to take to estimate the plane. As long as the plane is correct, the method that generated it will be given full marks. The second perception task that needs to be performed, is lane boundary detection. The output of the Hough transform line detection, is any line belonging to the boundary of the lane including horizontal ones and lines on the far side of sidewalks. Furthermore, each of the lane boundaries will have multiple associated output lines from the Hough transform line estimator. You are required to filter out all irrelevant lines and merge relevant lines to produce one line per lane boundary. To filter out the horizontal lines, we can rely on the slope of the estimated lines. Horizontal lines and images tend to have a slope very close to zero. However, we also want to remove heavily slanted lines. As such, a threshold is introduced as a lower limit of allowed slopes for the output of this filtering step. The exact value of this threshold needs to be determined empirically, try values between 0.1 and 0.3 for best results. Having removed horizontal lines from the output of the half transform, you will need to cluster similar lines and then merge them to produce a single line per lane boundary. A simple clustering algorithm would be to first choose a cluster center at random from the remaining filter lines, then add to the cluster any lines that have a similar slope or intercept to the cluster line. A line is considered close to the cluster center if the difference between its slope and slope of the cluster center is less than a specific slope threshold, and the distance between its intercept and the intercept of the cluster center is less than a specific intercept threshold as well. The slope difference threshold is usually chosen to be a maximum of 0.3, while the intercept difference threshold is defined in pixels, and is usually chosen between 20 and 50 pixels. You will need to test various values before arriving at a satisfactory threshold for the assessment. The final step to produce one line per lane boundary, is to merge lines inside each cluster. The simplest way to do so is through averaging the slope and intercept of all cluster members. The final concept that you will need to finish the assessment, is how to filter out uncertain output of object detectors using the output from the semantic segmentation. The output of object detection is usually reliable. But for this assessment, you are given a high recall low precision detector that detects all objects in the scene, but also provides some false positives. You are required to use the output from semantic segmentation to eliminate these false positives before estimating the distance to the obstacles. The results should be bounding boxes that reliably contain obstacles. To perform this filtering, you will need to use the semantic segmentation output to count the number of pixels in the bounding box that have the same category as the classification output from the 2D object detector. The trick here, is that this number will depend on the size of the bounding box. You will need to normalize the pixel count by the area of the bounding box before attempting to filter out the detections with a threshold. The final normalized count is equivalent to computing the area inside the bounding box occupied by pixels belonging to the correct category. At this point, you should be ready to tackle the final assessment confidently. As a final note, I encourage you to think of different ways you could achieve the final output for the required tasks, other than the suggested outline. I hope you enjoy this assessment and find it beneficial to your learning.