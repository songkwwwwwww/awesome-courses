이 모듈의 첫 번째 수업에서, 우리는 의미론적 세분화 문제를 정의하고 클래스 IOU를 계산하여 의미론적 세분화 알고리즘의 성능을 평가하는 방법을 보았다. 이 비디오에서, 우리는 컨볼루션 신경망을 사용하여 의미론적 세분화 작업을 수행하는 방법을 배울 것입니다. 의미론적 세분화에 자신감을 사용하는 것은 실제로 물체 감지에 사용하는 것보다 조금 쉽다. 물체 감지를 위한 ConvNets와 달리, 훈련과 추론 단계는 의미론적 세분화를 위해 실질적으로 동일하다. 그러나, 우리가 알아야 할 의미론적 세분화에 대한 복잡성도 있다. 의미론적 세분화 문제에 대한 빠른 검토부터 시작합시다. 시맨틱 세분화는 카메라 이미지 입력을 취하고 해당 이미지의 모든 픽셀에 대한 카테고리 분류를 출력으로 제공합니다. 이 문제는 함수 근사치 문제로 모델링될 수 있으며, ConvNets는 필요한 함수를 근사하는 데 다시 한 번 사용될 수 있다. 이 함수 근사치를 수행하기 위해 어떤 종류의 ConvNet 모델을 사용할 수 있나요? 한 가지 아이디어는 우리가 물체 감지에 사용한 것과 동일한 ConvNet 모델을 사용하는 것이다. 즉, 기능 추출기 뒤에 출력 레이어가 뒤따른다. 우리는 물체를 현지화하려고 하지 않기 때문에 여기에 앵커가 필요하지 않습니다. 이 아키텍처가 의미론적 세분화를 수행하는 데 얼마나 효과적인지 봅시다. 기능 추출기를 분석하는 것으로 시작하겠습니다. 물체 감지를 위해 사용되는 기능 추출기와 마찬가지로, 우리는 VGG 아키텍처를 사용할 수 있습니다. 이 기능 추출기를 거치면서 M x N의 크기에 3개의 입력 이미지가 어떻게 되는지 봅시다. 물체 감지와 마찬가지로, 우리의 해상도는 모든 풀링 레이어 후에 절반으로 줄어들 것이다. 반면에, 우리의 깊이는 컨볼루션 층으로 인해 증가할 것이다. 우리의 컨볼루션 피처 추출기의 출력 피처 맵은 16번 다운샘플링될 것이다. 우리는 필요한 만큼의 컨볼루션 풀링 블록을 추가할 수 있지만, 그것은 우리의 기능 맵을 더욱 축소시킬 것이다. 그러나, 우리는 우리의 출력이 이미지의 모든 픽셀에 대해 분류되기를 원한다. 그렇다면 원래 입력보다 16배 작은 다운 샘플링 기능 맵을 감안할 때 이것을 어떻게 달성할 수 있을까요? 간단한 해결책은 다음과 같다. 먼저 소프트맥스 레이어를 통해 16번의 다운샘플링된 출력 기능 맵을 전달하여 출력을 계산할 수 있습니다. 그런 다음 소프트맥스 레이어가 얻은 가장 높은 클래스 점수를 취하여 서브샘플링된 출력의 모든 픽셀의 클래스를 결정할 수 있습니다. 마지막 단계는 다운샘플링된 출력을 원래 이미지 해상도로 되돌리는 것이다. 설명된 접근 방식이 얼마나 잘 작동할 것이라고 생각하십니까? 왜 순진한 업샘플링이 부적절한 결과를 낳을 수 있는지 이해하려면, 업샘플링이 이미지 해상도를 어떻게 증가시키는지 살펴봅시다. 우리는 2 x 2 이미지 패치에 가장 가까운 이웃 업샘플링을 사용하고 싶습니다. 이미지 패치의 픽셀 색상은 모든 픽셀의 다른 값을 나타냅니다. 우리는 원래 크기를 두 배로 늘리기 위해 패치를 업샘플링하고 싶습니다. 그래서 두 개의 업샘플링 승수 S를 가지세요. 가장 가까운 이웃 업샘플링은 Win an Hin에 업샘플링 승수를 곱하여 빈 초기 업샘플링 그리드를 생성합니다. 그런 다음 업샘플링된 그리드의 각 픽셀은 원본 이미지 패치에서 가장 가까운 픽셀 값으로 채워집니다. 이 과정은 업샘플링된 그리드의 모든 픽셀이 이미지 패치의 값으로 채워질 때까지 반복됩니다. 출력 업샘플링 그리드의 깊이는 입력 이미지 패치와 동일하게 유지됩니다. 업샘플링에 의해 유발된 문제는 업샘플링된 출력 이미지가 매우 거친 경계를 가지고 있다는 것이다. 마지막 수업에서 기억할 수 있듯이, 의미론적 세분화에서 가장 어려운 문제 중 하나는 물체 주변의 매끄럽고 정확한 경계를 달성하는 것입니다. 이미지 공간의 일반적인 경계에서 특히 수영장과 같은 얇은 물체, 도로와 보도와 같은 비슷한 모양의 물체, 멀리 떨어진 물체의 경우 모호하기 때문에 부드러운 경계는 달성하기 어렵다. 순진한 업샘플링은 또한 두 가지 추가적인 문제를 유발한다. 너비나 높이가 16픽셀 미만인 물체는 일반적으로 업샘플링된 이미지에서 완전히 사라집니다. 이것은 풀과 멀리 떨어진 물체와 같은 얇은 물체 모두에 영향을 미친다. 픽셀이 원본 이미지에서 나타나는 데 필요한 최소 치수보다 낮기 때문입니다. 이러한 문제를 해결하기 위해, 연구자들은 일반적으로 기능 디코더라고 불리는 것을 공식화했다. 기능 디코더는 기능 추출기의 거울 이미지로 생각할 수 있다. 컨볼루션 풀링 패러다임을 사용하여 해상도를 다운샘플링하는 대신, 업샘플링 레이어와 컨볼루션 레이어를 사용하여 기능 맵의 해상도를 업샘플링합니다. 일반적으로 가장 가까운 이웃 방법을 사용하는 업샘플링은 풀링과 반대의 효과를 얻지만, 부정확한 기능 맵을 초래한다. 그런 다음 다음 컨볼루션 레이어는 학습 가능한 필터 뱅크로 업샘플링된 기능 맵의 기능을 수정하는 데 사용됩니다. 이 수정은 일반적으로 기능 디코더를 진행할 때 필요한 부드러운 경계를 제공합니다. 이제 기능 디코더를 통해 앞으로 이동하면서 기능 맵의 크기를 분석해 봅시다. 다시 말씀드리지만, 입력 기능 맵은 깊이 512로 16번 다운샘플링됩니다. 기능 추출기와 마찬가지로, 각 업샘플링 컨볼루션 블록은 디컨볼루션이라고 불린다. 물론 현재 연구자들 사이에서 이 용어가 정확한지에 대한 논쟁이 있다. 하지만 우리는 컨볼루션 풀링 블록의 반대를 언급하기 위해 그것을 사용할 것이다. 첫 번째 디컨볼루션 블록을 거치면서, 우리의 입력 기능 맵은 입력 해상도의 두 배로 업샘플링됩니다. 깊이는 각 연속적인 컨볼루션 레이어에 대해 정의된 필터의 수에 따라 제어됩니다. 나머지 디코더를 진행하면서, 우리는 마침내 입력 이미지와 비슷한 해상도의 기능 지도에 도달합니다. 계산 복잡성을 줄이기 위해, 우리는 보통 앞으로 나아갈 때 지도의 깊이를 줄인다. 하지만 이것은 당신의 응용 프로그램에 따라 달라지는 디자인 선택입니다. 이 업샘플링 메커니즘은 제안된 많은 의미 세분화 방법 중 가장 간단합니다. 의미 세분화를 위해 제안된 보다 효율적이고 강력하며 복잡한 업샘플링 모델을 위해 제공된 보충 자료를 살펴보세요. 이제 입력 이미지와 비슷한 크기의 기능 맵을 가지고 있으므로, 의미론적 세분화 출력을 생성해야 합니다. 선형 출력 레이어를 통해 시맨틱 세분화를 수행하고 소프트맥스 함수를 수행할 수 있습니다. 이 레이어는 객체 탐지에서 설명한 분류 출력 레이어와 매우 유사합니다. 사실, 이 레이어는 픽셀당 k차원 벡터를 제공하며 kth 요소는 신경망이 픽셀이 kth 클래스에 속한다는 것을 얼마나 확신하는지 알고 있다. 예상 출력을 시각적으로 조사해 봅시다. 이미지 패치와 해당 지상 진실 라벨이 주어지면, 우리는 각 픽셀을 k차원 원샷 벡터로 표현할 수 있습니다. 하나의 핫 벡터는 하나의 값을 올바른 클래스에 할당하고 나머지 클래스에 0을 할당합니다. 그 하나의 값만이 0이 아니거나 뜨겁기 때문이다. 이 경우, 우리는 두 개의 클래스와 배경 클래스가 있으므로 픽셀당 3차원 지상 진실 벡터로 작업하고 있습니다. 신경망은 softmax의 출력을 올바른 클래스에 대해 가능한 한 가깝게 구동하며, 각 픽셀의 나머지 클래스에 대해 가능한 한 0에 가깝다. 그런 다음 필요한 출력 표현을 복구하기 위해 최대 점수의 인덱스를 가져옵니다. 그러나, 우리는 추론 중에만 이 단계를 수행한다는 점에 유의하십시오. 훈련을 위해, 우리는 softmax 출력 점수를 직접 사용합니다. 정의상 의미론적 세분화의 문제는 신경망이 모든 픽셀 분류에 대해 단일 클래스를 제공하도록 요구한다. 이 작업을 수행하는 방법을 배우기 위해, 교차 엔트로피 분류 손실은 신경망을 다시 한 번 훈련시키는 데 사용됩니다. 이 손실은 우리가 물체 감지 분류 히트를 위해 사용한 것과 비슷하다. 교차 엔트로피는 지상 진실 클래스 확률 분포에 가장 가까운 픽셀당 확률 분포를 배우기 위해 신경망을 구동한다. 여기서, 총 N은 미니 배치의 모든 이미지에서 분류된 픽셀의 총 수입니다. 보통, 미니 배치는 8개에서 16개의 이미지로 구성되며, 이 숫자의 선택은 GPU가 얼마나 많은 메모리를 가지고 있는지에 달려 있습니다. 마지막으로, 교차 엔트로피 손실은 Si, 모든 픽셀의 신경망 출력과 Si star, 그 픽셀의 지상 진실 분류를 비교한다. 요약하면, 우리는 의미론적 세분화를 위해 다음과 같은 ConvNet 모델에 도달했다. 기능 추출기는 이미지를 입력으로 가져와 표현력이 뛰어나지만 저해상도 기능 맵을 출력으로 제공합니다. 그런 다음 디코더는 이 기능 맵을 가져와 업샘플하여 원본 입력 이미지와 동일한 해상도의 최종 피처 맵을 얻습니다. 마지막으로, 선형 레이어 뒤에 softmax 함수가 입력 이미지의 각 픽셀에 대해 ConvNets 클래스 벡터를 생성합니다. 우리가 이 수업에서 설명한 아키텍처는 의미론적 세분화에 사용할 수 있는 더 간단한 모델 중 하나이다. 의미 세분화를 위한 최적의 신경망 모델에 대한 많은 연구가 수행되었다. 추출기의 풀링 레이어에서 디코더의 업샘플링 레이어에 이르기까지 인덱스를 전파하는 것과 같은 아이디어는 시맨틱 세분화 모델의 성능 향상과 계산 속도를 제공하는 것으로 나타났다. 우리는 보충 자료에 의미론적 세분화에 사용되는 아키텍처를 설명하는 최근 원고 목록을 포함시켰습니다. 축하합니다, 이제 의미론적 세분화 문제를 해결하기 위해 ConvNets를 사용하는 기본 사항을 이해해야 합니다. 대부분의 최첨단 세분화 네트워크는 우리가 이 비디오에서 설명한 구조를 공유합니다. 기능 추출기, 디코더 및 주요 빌딩 블록으로 출력 레이어를 사용합니다. 현재 최고 성능의 알고리즘에 대해 더 깊이 파고들고 싶다면 최근 방법에 대한 몇 가지 링크를 참조로 제공합니다. 다음 수업에서, 우리는 자율주행 자동차가 보이는 도로를 인식할 수 있도록 의미론적 세분화 출력을 사용하는 방법을 설명할 것이다. 다음에 보자.